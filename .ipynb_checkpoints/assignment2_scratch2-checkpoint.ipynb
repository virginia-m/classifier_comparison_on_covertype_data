{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'codes' from '/Users/pmccauley/analysis/comp5318/comp5318_assignment_2/codes/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn import naive_bayes as nb\n",
    "from sklearn import neural_network as nn\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import codes as c\n",
    "\n",
    "import importlib\n",
    "importlib.reload(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_covtype(crop=False):\n",
    "    '''\n",
    "    Name:\n",
    "        read_covtype\n",
    "    \n",
    "    Purpose: \n",
    "        Read covtype dataset using the sklearn.datasets function fetch_covtype \n",
    "        and return in X, y array format along with class name and number arrays\n",
    "    \n",
    "    Parameters: \n",
    "        No Required Inputs:\n",
    "        \n",
    "        1 Optional Settings:\n",
    "        \n",
    "        (crop) = Boolean, default=Fales. Set to only keep the first 10 columns\n",
    "                 of X, which encode the most information\n",
    "    \n",
    "    Returns: \n",
    "        4 Ouputs: \n",
    "        \n",
    "        1 (X) = NumPy array, data array\n",
    "        2 (y) = NumPy array, class labels\n",
    "        3 (cnames) = list, class names\n",
    "        4 (cnums) = NumPy array, class number (numeric class labels)\n",
    "    '''     \n",
    "    \n",
    "    data = fetch_covtype()\n",
    "    X = data['data']\n",
    "    y = data['target']\n",
    "    \n",
    "    if crop==True:\n",
    "        X = X[:,0:10]\n",
    "    \n",
    "    cnames = ['Spruce/Fir','Lodgepole Pine','Ponderosa Pine','Cottonwood/Willow','Aspen','Douglas-fir','Krummholz']\n",
    "    cnums = np.arange(1,8)\n",
    "    \n",
    "    return X, y, cnames, cnums\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covtype_naive_bayes(X, y, kfold=10, style='prop'):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = c.split_dataset(X,y,regularize=False)\n",
    "    \n",
    "    _classifier = nb.GaussianNB\n",
    "    \n",
    "    confs = c.cross_validate_classifier(_classifier, X, y-1, kfold=kfold, style=style)\n",
    "    \n",
    "    conf = np.mean(confs, axis=0)\n",
    "    df_total, df_class, df_conf = c.metrics_wrapper(conf, cnames, do_display=True)\n",
    "    \n",
    "    return df_total, df_class, df_conf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, cnames, cnums = read_covtype(crop=False)\n",
    "df_total, df_class, df_conf = covtype_naive_bayes(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multi-Layer Perceptron (MLP)</h2>\n",
    "\n",
    "The following two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mlp_explore_param(param, values, X_train, y_train, X_test, y_test, args=None, redo=False):\n",
    "    '''\n",
    "    Name:\n",
    "        mlp_explore_param\n",
    "    \n",
    "    Purpose: \n",
    "        Explore a given scikit-learn MLP hyperparameter by looping through an \n",
    "        array of values and recording classification performance for each step. \n",
    "        Results are be written to CSV files and read from there on subsequent \n",
    "        calls unless redo=True.\n",
    "    \n",
    "    Parameters: \n",
    "        6 Required Inputs:\n",
    "        \n",
    "        1 (param) = String, hyperparameter to test (e.g. 'hidden_layer_sizes')\n",
    "        2 (values) = List or numpy array containing param values to be tested\n",
    "        3 (X_train) = NumPy array, Training data\n",
    "        4 (y_train) = NumPy array, Training labels\n",
    "        5 (X_test) = NumPy array, Test data\n",
    "        6 (y_test) = NumPy array, Test labels\n",
    "        \n",
    "        2 Optional Settings:\n",
    "        \n",
    "        1 (args) = Dictionary, default={'solver':'sgd', 'early_stopping':True}. \n",
    "                   Arguments passed to the MLP classifier via **kwargs that \n",
    "                   will be kept constant for each test\n",
    "        2 (redo) = Boolean, default=False. Results will be written to and read \n",
    "                   from a CSV file. Set redo=True to remake an existing CSV\n",
    "        \n",
    "    \n",
    "    Returns: \n",
    "        Out: Pandas DataFrame containing the metrics (accuracy, f1, precision, \n",
    "             recall, run time, loss, and iteration count) for each parameter value\n",
    "    ''' \n",
    "    \n",
    "    kwargs = args if args != None else {'solver':'sgd', 'early_stopping':True}\n",
    "    \n",
    "    if param not in kwargs:\n",
    "        kwargs = {**kwargs, **{param:values[0]}}\n",
    "\n",
    "    runtimes = np.zeros(np.shape(values)[0])\n",
    "    n_iter = np.zeros(np.shape(values)[0])\n",
    "    loss = np.zeros(np.shape(values)[0])\n",
    "        \n",
    "    if param=='learning_rate_init' or param=='tol':\n",
    "        file = Path('mlp_explore_results/mlp_explore_'+param+'_'+kwargs['learning_rate']+'.csv')\n",
    "    elif param=='hidden_layer_sizes':\n",
    "        config = 'depth' if type(values)==list else 'width'\n",
    "        file = Path('mlp_explore_results/mlp_explore_'+param+'_'+config+'.csv')\n",
    "    else:\n",
    "        file = Path('mlp_explore_results/mlp_explore_'+param+'.csv')\n",
    "    \n",
    "    if file.is_file()==True and redo==False:\n",
    "        \n",
    "        print('Reading existing results from '+file.name)\n",
    "        df_totals = pd.read_csv(file.resolve(), index_col=0)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        print('Exploring param = '+param+' from '+str(values[0])+' to '+str(values[-1]))\n",
    "        print('Working on '+param+' = ', sep=' ', end='', flush=True)\n",
    "    \n",
    "        for i, param_value in enumerate(values):\n",
    "            kwargs[param] = param_value\n",
    "            print(param_value, sep=' ', end=',', flush=True)\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            _classifier = nn.MLPClassifier(**kwargs)\n",
    "            _classifier = _classifier.fit(X_train, y_train)\n",
    "            y_pred = _classifier.predict(X_test)\n",
    "            \n",
    "            runtimes[i] = time.time()-start\n",
    "            n_iter[i] = _classifier.n_iter_\n",
    "            loss[i] = _classifier.loss_\n",
    "            \n",
    "            conf = c.construct_confusion_matrix(y_test-1, y_pred-1, dim=7)\n",
    "            df_total, df_class, df_conf = c.metrics_wrapper(conf, cnames, do_display=False)\n",
    "\n",
    "            df_totals = df_total.copy() if i==0 else df_totals.append(df_total, ignore_index=True)\n",
    "\n",
    "        df_totals.insert(0, 'n_iter', n_iter)    \n",
    "        df_totals.insert(0, 'loss', loss)    \n",
    "        df_totals.insert(0, 'Run Time', runtimes)\n",
    "        df_totals.insert(0, param, values)\n",
    "\n",
    "        df_totals.to_csv(path_or_buf=file)\n",
    "        print(' ', sep='\\newline')\n",
    "        print('Wrote results to '+file.name)\n",
    "    \n",
    "    return df_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mlp_explore_params(X_train, y_train, X_test, y_test, redo=False):\n",
    "    '''\n",
    "    Name:\n",
    "        mlp_explore_params\n",
    "    \n",
    "    Purpose: \n",
    "        Explore scikit-learn MLP hyperparameters by looping through an \n",
    "        arrays possible values. This code is wrapper for mlp_explore_param \n",
    "        that defines the the values to be tested and passes them to the main \n",
    "        routine. \n",
    "    \n",
    "    Parameters: \n",
    "        4 Required Inputs:\n",
    "    \n",
    "        1 (X_train) = NumPy array, Training data\n",
    "        2 (y_train) = NumPy array, Training labels\n",
    "        3 (X_test) = NumPy array, Test data\n",
    "        4 (y_test) = NumPy array, Test labels\n",
    "        \n",
    "        2 Optional Settings:\n",
    "        \n",
    "        2 (redo) = Boolean, default=False. Results will be written to and read \n",
    "                   from CSV filee. Set redo=True to remake existing CSVe\n",
    "        \n",
    "    \n",
    "    Returns: \n",
    "        Out: List with Pandas DataFrames containing the metrics (accuracy, f1, precision, \n",
    "             recall, run time, loss, and iteration count) for each parameter value\n",
    "    ''' \n",
    "    \n",
    "    \n",
    "    params = ['hidden_layer_sizes', \\\n",
    "              'hidden_layer_sizes', \\\n",
    "              'activation', \\\n",
    "              'alpha', \\\n",
    "              'batch_size', \\\n",
    "              'momentum', \\\n",
    "              'learning_rate_init', \\\n",
    "              'shuffle', \\\n",
    "              'nesterovs_momentum', \\\n",
    "              'power_t', \\\n",
    "              'tol']\n",
    "    \n",
    "    values = [np.append([np.arange(1,10,1),np.arange(10,100,10)],np.arange(100,1100,100)), \\\n",
    "              [[100],[100,100],[100,100,100],[100,100,100,100],[100,100,100,100,100]], \\\n",
    "              ['identity', 'logistic', 'tanh', 'relu'], \\\n",
    "              np.sort(np.append(np.geomspace(1e-6,1e-1,num=6),np.geomspace(5e-6,5e-1,num=6))), \\\n",
    "              np.sort(np.append(np.geomspace(1e1,1e5,num=5),np.geomspace(5e1,5e4,num=4))).round().astype(int), \\\n",
    "              np.linspace(0.01, 0.99, 50), \\\n",
    "              np.sort(np.append(np.geomspace(1e-5,1e0,num=6),np.geomspace(5e-5,5e-1,num=5))), \\\n",
    "              [False,True], \\\n",
    "              [False,True], \\\n",
    "              np.linspace(0.1, 2, 20), \\\n",
    "              np.sort(np.append(np.geomspace(1e-6,1e1,num=8),np.geomspace(5e-6,5e0,num=7)))]\n",
    "    \n",
    "    learning_rates = ['constant','invscaling','adaptive']\n",
    "    \n",
    "    base_args = {'solver':'sgd', 'early_stopping':True}\n",
    "    \n",
    "    output = []\n",
    "    for i, param in enumerate(params):\n",
    "        \n",
    "        if param=='learning_rate_init' or param=='tol':\n",
    "            for rate in learning_rates:\n",
    "                args = {**base_args, **{'learning_rate':rate}}\n",
    "                df_totals = mlp_explore_param(param, values[i], X_train, y_train, X_test, y_test, args=args, redo=redo)\n",
    "        \n",
    "        elif param=='power_t':\n",
    "            args = {**base_args, **{'learning_rate_init':0.1, 'learning_rate':'invscaling'}}\n",
    "            df_totals = mlp_explore_param(param, values[i], X_train, y_train, X_test, y_test, redo=redo)\n",
    "            \n",
    "        else:\n",
    "            df_totals = mlp_explore_param(param, values[i], X_train, y_train, X_test, y_test, redo=redo)\n",
    "                    \n",
    "        output.append(df_totals)\n",
    "        \n",
    "    return output, params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing results from mlp_explore_hidden_layer_sizes_width.csv\n",
      "Reading existing results from mlp_explore_hidden_layer_sizes_depth.csv\n",
      "Reading existing results from mlp_explore_activation.csv\n",
      "Reading existing results from mlp_explore_alpha.csv\n",
      "Reading existing results from mlp_explore_batch_size.csv\n",
      "Reading existing results from mlp_explore_momentum.csv\n",
      "Reading existing results from mlp_explore_learning_rate_init_constant.csv\n",
      "Reading existing results from mlp_explore_learning_rate_init_invscaling.csv\n",
      "Reading existing results from mlp_explore_learning_rate_init_adaptive.csv\n",
      "Reading existing results from mlp_explore_shuffle.csv\n",
      "Reading existing results from mlp_explore_nesterovs_momentum.csv\n",
      "Reading existing results from mlp_explore_power_t.csv\n",
      "Reading existing results from mlp_explore_tol_constant.csv\n",
      "Reading existing results from mlp_explore_tol_invscaling.csv\n",
      "Reading existing results from mlp_explore_tol_adaptive.csv\n"
     ]
    }
   ],
   "source": [
    "X, y, cnames, cnums = read_covtype(crop=False)\n",
    "X_train, y_train, X_test, y_test = c.split_dataset(X,y,regularize=True)\n",
    "\n",
    "tables, params = mlp_explore_params(X_train, y_train, X_test, y_test, redo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hidden layer number = mean([features,columns])\n",
    "start = time.time()\n",
    "\n",
    "kwargs = mlp_args()\n",
    "\n",
    "_classifier = nn.MLPClassifier(**kwargs)\n",
    "_classifier = _classifier.fit(X_train, y_train)\n",
    "y_pred = _classifier.predict(X_test)\n",
    "print((time.time()-start)/60)\n",
    "\n",
    "conf = c.construct_confusion_matrix(y_test-1, y_pred-1, dim=7)\n",
    "df_total, df_class, df_conf = c.metrics_wrapper(conf, cnames, do_display=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
